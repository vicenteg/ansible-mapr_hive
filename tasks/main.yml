---
# tasks file for mapr-hive
# mysql_root_password comes from top-level group_vars/all

- name: install mysqldb which is required for ansible
  become: yes
  become_user: root
  yum: name=MySQL-python state=present

- name: install hive {{hive_version}} and related packages
  become: yes
  become_user: root
  yum: name={{item}} state=present
  with_items:
    - mysql
    - 'mapr-hive-{{hive_version}}*'
    - 'mapr-hiveserver2-{{hive_version}}*'
  notify: reconfigure roles

- name: install hive {{hive_version}} metastore
  become: yes
  become_user: root
  yum: name={{item}} state=present
  with_items:
    - 'mapr-hivemetastore-{{hive_version}}*'
  notify: reconfigure roles

- name: store the path to hive
  shell: rpm -ql mapr-hive  | head -2 | tail -1
  register: hive_home
  changed_when: false

- name: ensure the top level hive directory is owned by mapr so logs directory can be created
  become: yes
  become_user: root
  file: path=/opt/mapr/hive owner={{mapr_admin_username}} group={{mapr_admin_username}} recurse=yes

# Note that this template may rely on variables in other groups, and as a result, 
# my not always work when this playbook is run individually.
- name: write .my.cnf for root
  become: yes
  become_user: root
  template: src=dot-my.cnf.j2 dest=/root/.my.cnf mode=0600 owner=root group=root

- name: create mapr user@localhost
  mysql_user:
    name={{hive_db_user}}
    host="localhost"
    password="{{hive_db_pass}}"
    check_implicit_admin=yes
    priv={{hive_db}}.*:ALL
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  with_items:
    - "{{ansible_default_ipv4.address}}"
    - "{{ansible_hostname}}"
    - "%"

- name: create mapr user@%
  mysql_user:
    name={{hive_db_user}}
    host={{item}}
    password={{hive_db_pass}}
    check_implicit_admin=yes
    priv={{hive_db}}.*:ALL
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  with_items:
    - "{{ansible_default_ipv4.address}}"
    - "{{hostvars[hive_metastore_host].ansible_hostname}}"
    - "{{hostvars[hive_metastore_host].ansible_fqdn}}"
    - "%"

- name: remove world-read permission from hive-site.xml (contains metastore DB password)
  become: yes
  become_user: root
  file: path=/opt/mapr/hive/hive-{{hive_version}}/conf/hive-site.xml mode=0640

- name: enable SASL auth with encryption when secure
  hadoop_properties: name=hive.server2.thrift.sasl.qop value=auth-conf file={{hive_home.stdout}}/conf/hive-site.xml state=present
  become: yes
  become_user: '{{mapr_admin_username}}'
  when: secure_cluster is defined and secure_cluster == True
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set metastore URI
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.metastore.uris value={% for node in groups['hiveserver'] -%}thrift://{{ hostvars[node].ansible_fqdn }}:{{hivemeta_thrift_port}}{% if not loop.last %},{% endif %}{% endfor %}  state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set JDBC URL for the metastore
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=javax.jdo.option.ConnectionURL value=jdbc:mysql://{{hostvars[hive_metastore_host].ansible_hostname}}:3306/{{hive_db}}?createDatabaseIfNotExist=true state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set datanucleus.schema.autoCreateTables
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=datanucleus.schema.autoCreateTables value=true state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set hiveserver2 thrift port
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.server2.thrift.port value={{hiveserver2_thrift_port}} file={{hive_home.stdout}}/conf/hive-site.xml state=present
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set hive metastore user
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=javax.jdo.option.ConnectionUserName value={{hive_db_user}} state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set hive metastore password
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=javax.jdo.option.ConnectionPassword value={{hive_db_pass}} state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: disable impersonation when insecure
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name={{item}} state=present value="false" file={{hive_home.stdout}}/conf/hive-site.xml
  with_items:
    - "hive.metastore.execute.setugi"
    - "hive.server2.enable.doAs"
    - "hive.security.metastore.authorization.auth.reads"
  notify:
    - restart hivemeta
    - restart hiveserver2
  when: secure_cluster is defined and secure_cluster == False

- name: enable impersonation
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name={{item}} state=present value="true" file={{hive_home.stdout}}/conf/hive-site.xml
  with_items:
    - "hive.metastore.execute.setugi"
    - "hive.server2.enable.doAs"
    - "hive.security.metastore.authorization.auth.reads"
  notify:
    - restart hivemeta
    - restart hiveserver2
  when: secure_cluster is defined and secure_cluster

- name: turn on storage side metastore security
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.metastore.pre.event.listeners state=present value=org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable storage authn
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.security.metastore.authenticator.manager state=present value=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable storage based authz
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.security.metastore.authorization.manager state=present value=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2


- name: enable hive2 PAM authentication
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.server2.authentication value=PAM file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == True and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable hive2 MapR SASL authentication
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.server2.authentication value=MAPRSASL file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == True and hive_authentication_type == "maprsasl"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable SSL
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.server2.use.SSL value=true file={{hive_home.stdout}}/conf/hive-site.xml state=present
  when: secure_cluster is defined and secure_cluster == True and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set path to ssl_keystore
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.server2.keystore.path value=/opt/mapr/conf/ssl_keystore file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == True and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set password to ssl_keystore
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.server2.keystore.password value=mapr123 file={{hive_home.stdout}}/conf/hive-site.xml state=present
  when: secure_cluster is defined and secure_cluster == True and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set PAM authentication services
  become: yes
  become_user: '{{mapr_admin_username}}'
  hadoop_properties: name=hive.server2.authentication.pam.services value={{hive_pam_services}} file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == True and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

# XXX: this directory should not be hard coded
- name: does hive warehouse directory exist?
  become: yes
  become_user: '{{mapr_admin_username}}'
  command: hadoop fs -test -d /user/hive/warehouse
  register: warehouse_exists
  failed_when: warehouse_exists.rc not in (0,1,255)
  changed_when: false

# Cannot do this when in secure mode without logging in
- name: create hive warehouse directory
  become: yes
  become_user: '{{mapr_admin_username}}'
  command: hadoop fs -mkdir -p /user/hive/warehouse
  when: warehouse_exists.rc in (1,255)

# Cannot do this when in secure mode without logging in
- name: set permissions on warehouse directory
  become: yes
  become_user: '{{mapr_admin_username}}'
  command: hadoop fs -chmod 1777 /user/hive/warehouse

- name: give warden a little time to find hive services
  pause: seconds=30

- name: execute handlers now
  meta: flush_handlers

- name: get the active hs2
  become: yes
  become_user: '{{mapr_admin_username}}'
  shell: maprcli node list -filter svc==hs2 -columns hostname -noheader | awk '{print $1}'
  register: active_hs2

- name: get the active hivemeta
  become: yes
  become_user: '{{mapr_admin_username}}'
  shell: maprcli node list -filter svc==hivemeta -columns hostname -noheader | awk '{print $1}'
  register: active_hivemeta

- name: wait for hivemeta to be listening
  wait_for: host={{active_hivemeta.stdout}} port={{hivemeta_thrift_port}} timeout=60
  run_once: yes
  tags: test
  
- name: wait for hs2 to be listening
  wait_for: host={{active_hs2.stdout}} port={{hiveserver2_thrift_port}} timeout=60
  run_once: yes
  tags: test
