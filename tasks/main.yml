---
# tasks file for mapr-hive
# mysql_root_password comes from top-level group_vars/all

- name: install mysqldb which is required for ansible
  yum: name=MySQL-python state=present
  environment: proxy_env

- name: install hive $hive_version and related packages
  yum: name={{item}} state=present
  with_items:
    - mysql
    - 'mapr-hive-{{hive_version}}*'
    - 'mapr-hiveserver2-{{hive_version}}*'
    - 'mapr-hivemetastore-{{hive_version}}*'
  notify: reconfigure roles
  environment: proxy_env

- name: store the path to hive
  shell: rpm -ql mapr-hive  | head -2 | tail -1
  register: hive_home
  changed_when: false

- name: ensure the top level hive directory is owned by mapr so logs directory can be created
  file: path=/opt/mapr/hive owner=mapr group=mapr recurse=yes

# Note that this template may rely on variables in other groups, and as a result, 
# my not always work when this playbook is run individually.
- name: write .my.cnf for root
  template: src=dot-my.cnf.j2 dest=/root/.my.cnf mode=0600 owner=root group=root

- name: ensure hive metastore database exists
  mysql_db:
    name="{{hive_db}}"
    state=present
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  register: db_changed

- name: check for metastore table
  command: mysql -u {{mysql_root_user}} --password={{mysql_root_password}} {{hive_db}} -e 'show tables'
  register: metastore_tables
  changed_when: false
  no_log: True

- name: create the hive metastore schema for hive 0.12
  mysql_db:
    name="{{hive_db}}"
    state=import
    target="{{hive_home.stdout}}/scripts/metastore/upgrade/mysql/hive-schema-0.12.0.mysql.sql"
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  when: metastore_tables.stdout|length == 0 and '0.12' in hive_version

- name: create the hive metastore schema for hive 0.13
  mysql_db:
    name="{{hive_db}}"
    state=import
    target="{{hive_home.stdout}}/scripts/metastore/upgrade/mysql/hive-schema-0.13.0.mysql.sql"
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  when: metastore_tables.stdout|length == 0 and '0.13' in hive_version

- name: create the hive metastore schema for hive 0.14 or 1.0
  mysql_db:
    name="{{hive_db}}"
    state=import
    target="{{hive_home.stdout}}/scripts/metastore/upgrade/mysql/hive-schema-0.14.0.mysql.sql"
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  when: metastore_tables.stdout|length == 0 and '1.0' in hive_version

- name: create mapr user@localhost
  mysql_user:
    name={{hive_db_user}}
    host="localhost"
    password="{{hive_db_pass}}"
    check_implicit_admin=yes
    priv={{hive_db}}.*:ALL
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  with_items:
    - "{{ansible_default_ipv4.address}}"
    - "{{ansible_hostname}}"
    - "%"

- name: create mapr user@%
  mysql_user:
    name={{hive_db_user}}
    host={{item}}
    password={{hive_db_pass}}
    check_implicit_admin=yes
    priv={{hive_db}}.*:ALL
    login_user="{{mysql_root_user}}"
    login_password="{{mysql_root_password}}"
    login_host="{{hostvars[hive_metastore_host].ansible_hostname}}"
  with_items:
    - "{{ansible_default_ipv4.address}}"
    - "{{hostvars[hive_metastore_host].ansible_hostname}}"
    - "{{hostvars[hive_metastore_host].ansible_fqdn}}"
    - "%"

#- name: copy hive-site.xml into place
#  template: src=hive-site.xml.j2 dest="{{hive_home.stdout}}/conf/hive-site.xml"

- name: enable SASL auth with encryption when secure
  hadoop_properties: name=hive.server2.thrift.sasl.qop value=auth-conf file={{hive_home.stdout}}/conf/hive-site.xml state=present
  when: secure_cluster is defined and secure_cluster == "True"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set metastore URI
  hadoop_properties: name=hive.metastore.uris value=thrift://{{hostvars[hive_metastore_host].ansible_hostname}}:{{hivemeta_thrift_port}} state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set JDBC URL for the metastore
  hadoop_properties: name=javax.jdo.option.ConnectionURL value=jdbc:mysql://{{hostvars[hive_metastore_host].ansible_hostname}}:3306/{{hive_db}} state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set hiveserver2 thrift port
  hadoop_properties: name=hive.server2.thrift.port value={{hiveserver2_thrift_port}} file={{hive_home.stdout}}/conf/hive-site.xml state=present
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set hive metastore user
  hadoop_properties: name=javax.jdo.option.ConnectionUserName value={{hive_db_user}} state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set hive metastore password
  hadoop_properties: name=javax.jdo.option.ConnectionPassword value={{hive_db_pass}} state=present file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable impersonation (if secure_cluster)
  hadoop_properties: name={{item}} state=present value="true" file={{hive_home.stdout}}/conf/hive-site.xml
  with_items:
    - "hive.metastore.execute.setugi"
    - "hive.server2.enable.doAs"
    - "hive.security.metastore.authorization.auth.reads"
  when: secure_cluster is defined and secure_cluster == "True"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: turn on storage side metastore security if secure_cluster)
  hadoop_properties: name=hive.metastore.pre.event.listeners state=present value=org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == "True"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable storage authn (if secure_cluster)
  hadoop_properties: name=hive.security.metastore.authenticator.manager state=present value=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == "True"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable storage based authz (if secure_cluster)
  hadoop_properties: name=hive.security.metastore.authorization.manager state=present value=org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == "True"
  notify:
    - restart hivemeta
    - restart hiveserver2


- name: enable hive2 PAM authentication
  hadoop_properties: name=hive.server2.authentication value=PAM file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == "True" and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable hive2 MapR SASL authentication
  hadoop_properties: name=hive.server2.authentication value=MAPRSASL file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == "True" and hive_authentication_type == "maprsasl"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: enable SSL
  hadoop_properties: name=hive.server2.use.SSL value=true file={{hive_home.stdout}}/conf/hive-site.xml state=present
  when: secure_cluster is defined and secure_cluster == "True" and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set path to ssl_keystore
  hadoop_properties: name=hive.server2.keystore.path value=/opt/mapr/conf/ssl_keystore file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == "True" and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set password to ssl_keystore
  hadoop_properties: name=hive.server2.keystore.password value=mapr123 file={{hive_home.stdout}}/conf/hive-site.xml state=present
  when: secure_cluster is defined and secure_cluster == "True" and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set PAM authentication services
  hadoop_properties: name=hive.server2.authentication.pam.services value={{hive_pam_services}} file={{hive_home.stdout}}/conf/hive-site.xml
  when: secure_cluster is defined and secure_cluster == "True" and hive_authentication_type == "pam"
  notify:
    - restart hivemeta
    - restart hiveserver2

- name: set hive metastore server
  hadoop_properties: name="hive.metastore.uris" state=present value="thrift://{{hostvars[hive_metastore_host].ansible_hostname}}:{{hivemeta_thrift_port}}" file={{hive_home.stdout}}/conf/hive-site.xml
  notify:
    - restart hivemeta
    - restart hiveserver2

# XXX: this directory should not be hard coded
- name: does hive warehouse directory exist?
  sudo: yes
  sudo_user: '{{mapr_admin_username}}'
  command: hadoop fs -test -d /user/hive/warehouse
  register: warehouse_exists
  failed_when: warehouse_exists.rc not in (0,1,255)
  changed_when: false

# Cannot do this when in secure mode without logging in
- name: create hive warehouse directory
  sudo: yes
  sudo_user: '{{mapr_admin_username}}'
  command: hadoop fs -mkdir -p /user/hive/warehouse
  when: warehouse_exists.rc in (1,255)

# Cannot do this when in secure mode without logging in
- name: set permissions on warehouse directory
  sudo: yes
  sudo_user: '{{mapr_admin_username}}'
  command: hadoop fs -chmod 1777 /user/hive/warehouse

- name: wait for hs2 and hivemeta to come up
  wait_for: port={{item}} timeout=60
  with_items:
    - '{{hivemeta_thrift_port}}'
    - '{{hiveserver2_thrift_port}}'
  
